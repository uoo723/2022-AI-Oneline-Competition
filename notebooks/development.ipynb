{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2296b1d2-bd7b-42ef-8784-c5eb5ac7e619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0029f84f-0ed7-48d3-8d9d-435c5a4852ce",
   "metadata": {},
   "source": [
    "# Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d2e5d8c-0c7d-4428-81a2-93b401c3ff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import OrderedDict, defaultdict\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from joblib import Parallel, delayed\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "\n",
    "from src.datasets import Dataset, bert_collate_fn\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d77b6ad-6a74-49c9-8299-f3c15848c721",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2057bd20-aac8-40c0-9a19-78edfe9dbae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of train data: 1,862\n",
      "# of test data: 827\n"
     ]
    }
   ],
   "source": [
    "train_data_path = \"./data/train.json\"\n",
    "test_data_path = \"./data/test_data.json\"\n",
    "with open(train_data_path, \"r\") as f1, open(test_data_path, \"r\") as f2:\n",
    "    train_data = json.load(f1)\n",
    "    test_data = json.load(f2)\n",
    "test_question = pd.read_csv(\"./data/test_questions.csv\", encoding=\"utf8\")\n",
    "sample = pd.read_csv(\"./data/sample_submission.csv\", encoding=\"utf8\")\n",
    "print(f\"# of train data: {len(train_data['data']):,}\")\n",
    "print(f\"# of test data: {len(test_data['data']):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f6cd2e-ac6b-4ad5-91e9-ebf707ab221f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of queries: 233,121\n",
      "# of documents: 137,335\n"
     ]
    }
   ],
   "source": [
    "train_queries = OrderedDict()\n",
    "train_query_to_docs = defaultdict(list)\n",
    "train_docs = OrderedDict()\n",
    "\n",
    "for data in train_data[\"data\"]:\n",
    "    for paragraph in data[\"paragraphs\"]:\n",
    "        for q in paragraph[\"qas\"]:\n",
    "            train_queries[q[\"question_id\"]] = q[\"question\"]\n",
    "            train_query_to_docs[q[\"question_id\"]].append(paragraph[\"paragraph_id\"])\n",
    "        train_docs[paragraph[\"paragraph_id\"]] = paragraph[\"context\"]\n",
    "\n",
    "print(f\"# of queries: {len(train_queries):,}\")\n",
    "print(f\"# of documents: {len(train_docs):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17e898cf-855a-4abf-a124-fbc8f60d7742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of query: 176\n",
      "Min length of query: 6\n",
      "Avg. length of query: 41.20\n",
      "Std. length of query: 12.99\n",
      "----------------------------------------\n",
      "Max length of document: 676\n",
      "Min length of document: 353\n",
      "Avg. length of document: 508.54\n",
      "Std. length of document: 72.12\n"
     ]
    }
   ],
   "source": [
    "query_lengths = np.array([len(q) for q in train_queries.values()])\n",
    "print(f\"Max length of query: {np.max(query_lengths):,}\")\n",
    "print(f\"Min length of query: {np.min(query_lengths):,}\")\n",
    "print(f\"Avg. length of query: {np.mean(query_lengths):.2f}\")\n",
    "print(f\"Std. length of query: {np.std(query_lengths):.2f}\")\n",
    "print(\"-\" * 40)\n",
    "doc_lengths = np.array([len(d) for d in train_docs.values()])\n",
    "print(f\"Max length of document: {np.max(doc_lengths):,}\")\n",
    "print(f\"Min length of document: {np.min(doc_lengths):,}\")\n",
    "print(f\"Avg. length of document: {np.mean(doc_lengths):.2f}\")\n",
    "print(f\"Std. length of document: {np.std(doc_lengths):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b03b718-4cdc-4fbb-9472-1b820b781ac9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef161a8c-84d5-43f4-83f0-2bd6275f1150",
   "metadata": {},
   "source": [
    "# BM25 Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e31a2699-f770-4e32-8547-0f97dacf1158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contents(data):\n",
    "    contents = []\n",
    "    for d in data[\"data\"]:\n",
    "        for paragraph in d[\"paragraphs\"]:\n",
    "            contents.append(\n",
    "                {\"id\": paragraph[\"paragraph_id\"], \"contents\": paragraph[\"context\"]}\n",
    "            )\n",
    "    return contents\n",
    "\n",
    "\n",
    "data_list = [\n",
    "    (train_data, \"./data/index/train/doc.json\"),\n",
    "    (test_data, \"./data/index/test/doc.json\"),\n",
    "]\n",
    "\n",
    "for data, index_path in data_list:\n",
    "    contents = get_contents(data)\n",
    "    os.makedirs(os.path.dirname(index_path), exist_ok=True)\n",
    "    with open(index_path, \"w\", encoding=\"utf8\") as f:\n",
    "        json.dump(contents, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705367c6-4b0f-4702-92ef-8dd8f8fabbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pyserini.index.lucene \\\n",
    "  --collection JsonCollection \\\n",
    "  --input data/index/train/ \\\n",
    "  --language ko \\\n",
    "  --index data/train.index \\\n",
    "  --generator DefaultLuceneDocumentGenerator \\\n",
    "  --threads 16 \\\n",
    "  --storePositions --storeDocvectors --storeRaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57453a31-0648-4b2d-8530-b192ba97e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pyserini.index.lucene \\\n",
    "  --collection JsonCollection \\\n",
    "  --input data/index/test/ \\\n",
    "  --language ko \\\n",
    "  --index data/test.index \\\n",
    "  --generator DefaultLuceneDocumentGenerator \\\n",
    "  --threads 16 \\\n",
    "  --storePositions --storeDocvectors --storeRaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3afc56c-258d-47cf-85d6-e13cc2e74cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher = LuceneSearcher(\"./data/test.index\")\n",
    "searcher.set_language(\"ko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "834b0508-13b4-448f-8030-cb2c84a625ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c16a40f21940bb99e6fd10e4e3a880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = []\n",
    "for q in tqdm(test_question[\"question_text\"]):\n",
    "    answer.append(\",\".join([r.docid for r in searcher.search(q, k=10)]))\n",
    "sample[\"paragraph_id\"] = answer\n",
    "sample.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f213db-b06f-4be4-8790-976da6dde631",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce83a13-56ba-4000-aa37-9d602595c4ce",
   "metadata": {},
   "source": [
    "# monoBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dac8ed8-9dcc-466e-b158-3b2f28ccd4b4",
   "metadata": {},
   "source": [
    "## First Stage Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be295391-8629-4fa6-9923-0a25d51936ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = list(train_queries.values())\n",
    "train_query_df = pd.DataFrame(data={\"q_id\": np.arange(len(queries)), \"query\": queries})\n",
    "\n",
    "batch_size = 10000\n",
    "num_batches = (len(train_query_df) + batch_size - 1) // batch_size\n",
    "\n",
    "for n in range(num_batches):\n",
    "    tsv_path = f\"./data/top1000/train_queries_{n:02d}.tsv\"\n",
    "    os.makedirs(os.path.dirname(tsv_path), exist_ok=True)\n",
    "    train_query_df[n : (n + 1) * batch_size].to_csv(\n",
    "        tsv_path, index=False, header=None, sep=\"\\t\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b6d402-0938-4ef8-9976-f0fec91ffc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pyserini.search.lucene \\\n",
    "  --index data/train.index \\\n",
    "  --topics data/top1000/train_queries_00.tsv \\\n",
    "  --output data/top1000/train_top1000_00.txt \\\n",
    "  --bm25 --language ko --hits 1000 --batch-size 256 --threads 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c6713f-d71b-414e-bf69-17431097248c",
   "metadata": {},
   "source": [
    "## PLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9396c79d-d15e-4b84-9848-195787e1e6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff56bca23de14efabcd5f352b3994b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/467 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fec417473e74e6cbf5ea406915eafd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/431M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_name = 'monologg/koelectra-base-v3-discriminator'\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "bert = AutoModel.from_pretrained(pretrained_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "128130b5-df95-46f0-8b78-6ac7b21188d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_1000 = [r.docid for r in searcher.search(queries[0], k=1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ae297402-57a8-4ae3-940c-5b6e66f264c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    train_queries, train_docs, train_query_to_docs, searcher, topk=1000, num_neg=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "cb15db94-3cec-4f92-be3c-0d01296d5a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('공기역학적 방사능 중간직경은 무엇을 분석하여 얻었어',\n",
       " ['방사성핵종 별 공기 부피당 방사능 농도(Bq/m3 )는 부피당 분진 농도(μg/L)와 질량당 방사능 농도(Bq/kg) 값을 이용하여 계산 가능하다. 분진이 흩날릴 가능성이 있는 작업 지점에 설치한 광학입자계수기(OPC, Optical Particle Counter)를 활용한 계측과 채취시료의 방사능분석 의뢰 등을 통하여 이 값들을 각각 얻을 수 있다. 선량환산인자(DCF, Dose Conversion Factor)는 원료물질 등이 함유한 방사성핵종의 종류 외에 분진 입자의 크기 및 분포, 밀도, 기하학적 모양, 흡수형태 등 물리화학적 형태에 따라 그 값이 크게 달라진다. 입자의 크기와 분포는 앞서 언급한 OPC를 분석하여 얻은 공기역학적 방사능 중간직경(AMAD, Activity Median Aerodynamic Diameter)과 직경분포에 따른 분산(GSD, Geometric Standard Deviation)으로 결정되며, 입자의 밀도는 Pycnometer 등의 밀도측정장비로 얻을 수 있다. 모양인자는 1로 통일하여 적용되는데 이 값은 1에 가까운 구형일수록 보수적인 평가가 이루어진다는 해외 연구결과를 바탕으로 볼 때 합리적이다.',\n",
       "  '셋째, 재난안전 R&D는 그 무엇보다도 학제적 접근이 필요하다. 재난은 단순히 과학기술의 문제가 아닌 모든 사회 문제가 결합된 융･복합적 사회 현상이다. 지진의 예측을 위해서는 지질학적 연구가 필요하지만, 지진을 대비하기 위해서는 내진 설계가 필요하고, 사회적으로 내진 설계를 요구하기 위해서는 효과적 규제 정책과 이를 감당할 수 있는 사회적 비용에 대한 철저한 분석이 필요하다. 또한 지진을 경험한 우리 국민들의 공포를 이해할 수 있는 심리적 접근과 함께 공동체가 재난 상황에서 효과적으로 협력하기 위한 사회학적 접근도 필수이다. 이처럼 재난이 융･복합적 성격을 가진 만큼 관련 R&D 역시 융･복합적일 필요가 있다. 현재 우리나라의 R&D는 철저히 과학기술적 방법론만을 강조하는 경향이 있다. 그러나 재난안전 R&D의 성과는 단순히 기술이 아니라 사회적 규제, 효과적 정부 정책인 경우가 더 많다. 이런 점을 고려하여 재난안전 R&D에 대한 학제적 접근 및 새로운 성과측정 방법론이 필요하다. '],\n",
       " [1, 0])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9f10ecde-229e-4e4f-a3f3-8574a8748642",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    [train_queries[q_id] for q_id in q_ids[:32]],\n",
    "    [train_docs[train_query_to_docs[q_id][0]] for q_id in q_ids[:32]],\n",
    "    return_tensors=\"pt\",\n",
    "    padding='max_length',\n",
    "    truncation='longest_first',\n",
    "    max_length=512,\n",
    "    # max_length=,\n",
    "    # truncation='',\n",
    "    # max_length=5,\n",
    "    # truncation='only_first',\n",
    "    # max_length=40,\n",
    "    # padding=True,\n",
    "    # truncation=\"only_first\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "000fb43b-a396-4905-957a-5c691529cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    collate_fn=partial(bert_collate_fn, tokenizer=tokenizer, max_length=512),\n",
    "    num_workers=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3546f101-7df6-4734-93aa-d8eac6cd85d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614ae6092f2a4e9cbe56e38979f37751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7286 [00:02<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _ in tqdm(dataloader):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
